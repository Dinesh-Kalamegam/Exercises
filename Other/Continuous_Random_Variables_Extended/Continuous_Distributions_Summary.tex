\documentclass[12pt]{article}
\usepackage[left=3cm,right=3cm,top=3cm,bottom=3cm]{geometry}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{tabularx}

\renewcommand\qedsymbol{\textbf{\emph{QED}}}
\begin{document}
\title{Summary of Continuous Distributions for a random Variable $X$}
\author{Dinesh Kalamegam}
\date{\today}
\maketitle

\section{Uniform $X \sim U(a,b)$}
\subsection{Probability Density Function $f(x)$}

\begin{equation*}
  f(x) =
  \begin{cases}
     \frac{1}{b-a} & a \leq x \leq b \\
     0 & \text{Otherwise}
  \end{cases}
\end{equation*}

\subsection{Cumulative Distribution Function $F(x)$}

\begin{equation*}
  F(x) =
  \begin{cases}
     0 & x <a \\
     \frac{x-a}{b-a} & a \leq x \leq b \\
     1 & x>b
  \end{cases}
\end{equation*}

\begin{proof}
  \begin{align*}
    F(X) &= \int_{a}^{b} f(u) du \\
         &= \left[\frac{u}{(b-a)}\right]_{a}^{x} \\
         &= \frac{x}{b-a} - \frac{a}{b-a} \\
         &= \frac{x-a}{b-a}
  \end{align*}
\end{proof}
\subsection{Moment Generating Function $M(t)=E(e^{tX})$}

\begin{equation*}
    M(t)=\frac{e^{tb}-e^{ta}}{t(b-a)}
\end{equation*}

\begin{proof}
\begin{align*}
  M(t) &= E(e^{tX})\\
       &= \int_{a}^{b} e^{tx} f(x) dx \\
       &= \int_{a}^{b} \frac{e^{tx}}{(b-a)} \\
       &= \left[\frac{e^{tx}}{t(b-a}) \right]_{a}^{b} \\
       &= \frac{e^{tb}-e^{ta}}{t(b-a)}
\end{align*}
\end{proof}

\subsection{$\bm{E(X)}$}

\begin{equation*}
  E(X) = \frac{a+b}{2} \\
\end{equation*}

\begin{proof}
  Symmetry Argument makes this proof \emph{trivial}
\end{proof}

\begin{proof} Integration
  \begin{align*}
    E(X) &= \int_{a}^{b} x f(x) dx \\
         &= \int_{a}^{b} \frac{x}{b-a} dx \\
         &= \left[\frac{x^{2}}{2(b-a)}\right]_{a}^{b} \\
         &= \frac{1}{2(b-a)}[b^{2}-a^{2}] \\
         &= \frac{1}{2(b-a)}[(b-a)(b+a)] \\
         &= \frac{a+b}{2}
  \end{align*}
\end{proof}

\subsection{$\bm{Var(X)}$}

\begin{equation*}
  Var(X)= \frac{(b-a)^{2}}{12}
\end{equation*}
\begin{proof} Integration
  \begin{align*}
    E(X^{2}) &= \int_{a}^{b} x^{2} f(x) dx \\
         &= \int_{a}^{b} \frac{x^{2}}{b-a} dx \\
         &= \left[\frac{x^{3}}{3(b-a)}\right]_{a}^{b} \\
         &= \frac{1}{3(b-a)}[b^{3}-a^{3}] \\
         &= \frac{1}{3(b-a)}[(b-a)(b^{2}+ab+a^{2})] \\
         &= \frac{a^{2}+ab+b^{2}}{3}
  \end{align*}

  Then we minus the two to obtain
  \begin{align*}
    Var(X) &= \frac{a^{2}+ab+b^{2}}{3} - \frac{(a+b)^{2}}{4} \\
           &= \frac{a^{2}+ab+b^{2}}{3} - \frac{a^{2}+2ab+b^{2}}{4} \\
           &= \frac{4a^{2}+4ab+4b^{2}}{12} - \frac{3a^{2}+6ab+3b^{2}}{12} \\
           &= \frac{a^{2}-2ab+b^{2}}{12} \\
           &= \frac{(b-a)^{2}}{12}
  \end{align*}
\end{proof}

\newpage
\section{Exponential $X \sim Exp(\lambda)$}
\subsection{Probability Density Function $f(x)$}

\begin{equation*}
  f(x) =
  \begin{cases}
     \lambda e^{-\lambda x} & x>0 \\
     0 & \text{Otherwise}
  \end{cases}
\end{equation*}

\subsection{Cumulative Distribution Function $F(x)$}
\begin{align*}
  F(x) &= 1-e^{-\lambda x} \text{ where $x>0$}\\
\end{align*}

\begin{proof}
  \begin{align*}
    F(x) &= \int_{0}^{x} \lambda e^{-\lambda u} du \\
         &= \left[-e^{-\lambda u} \right]_{0}^{x} \\
         &= (-e^{-\lambda x}) - (-1) \\
         &= 1 - e^{-\lambda x}
  \end{align*}
\end{proof}
\subsection{Moment Generating Function $M(t)=E(e^{tX})$}

\begin{equation*}
    M(t)=\frac{\lambda}{\lambda -t}
\end{equation*}
\begin{proof}
\begin{align*}
  M(t) &= E(e^{t}) \\
       &= \int_{\mathbb{R}} e^{tx} f(x) dx \\
       &= \int_{0}^{\infty} e^{tx} \cdot \lambda e^{-\lambda x} dxs \\
       &= \int_{0}^{\infty} \lambda e^{(t-\lambda)x} dx \\
       &= \left[\frac{\lambda}{(t-\lambda)}e^{(t-\lambda)x} \right]_{0}^{\infty} \\
       &= \frac{\lambda}{\lambda -t}
\end{align*}
\end{proof}
\subsection{$\bm{E(X)}$}

\begin{equation*}
  E(X) = \frac{1}{\lambda}
\end{equation*}

\begin{proof}
  \begin{align*}
    E(X) &= \int_{0}^{\infty} x f(x)\\
         &= \int_{0}^{\infty} x \lambda e^{-\lambda x} dx \\
         &= [-xe^{-\lambda x}]_{0}^{\infty} - \int_{0}^{\infty} -e^{-\lambda x} \\
         &= \left[-\frac{1}{\lambda} e^{-\lambda x} \right]_{0}^{\infty} \\
         &= 0 - \left(-\frac{1}{\lambda}\right) \\
         &= \frac{1}{\lambda}
  \end{align*}
\end{proof}
\subsection{$\bm{Var(X)}$}

\begin{equation*}
  Var(X)= \frac{1}{\lambda^{2}}
\end{equation*}
\begin{proof}
  \begin{align*}
    E(X^{2}) &= \int_{0}^{\infty} x^{2} f(x) dx \\
             &= \int_{0}^{\infty} x^{2} \lambda e^{-\lambda x} dx \\
             &= \left[-x^{2}e^{-\lambda x} \right]_{0}^{\infty} - \int_{0}^{\infty}-2x e^{-\lambda x} dx \\
             &= 2\int_{0}^{\infty} xe^{-\lambda x} \\
             &= 2\left[-\frac{1}{\lambda}xe^{-\lambda x} \right]_{0}^{\infty} -2 \int_{0}^{\infty}-\frac{1}{\lambda}e^{-x} \\
             &= 2\int_{0}^{\infty} \frac{1}{\lambda}e^{-\lambda x} dx \\
             &= 2\left[-\frac{1}{\lambda^{2}}e^{-\lambda x} \right]_{0}^{\infty} \\
             &= \frac{2}{\lambda^{2}} \\ \\
    Var(X) &= \frac{2}{\lambda^{2}} - \left(\frac{1}{\lambda}\right)^{2} \\
           &= \frac{1}{\lambda^{2}}
  \end{align*}
\end{proof}
\newpage
\section{Gamma $X \sim \Gamma(\alpha,\lambda)$}
\subsection{Probability Density Function $f(x)$}

\begin{equation*}
  f(x) =
  \begin{cases}
     \frac{\lambda^{\alpha} x^{\alpha -1} e^{-\lambda x}}{\Gamma(\alpha)} & x \geq 0 \\
     0 & \text{Otherwise}
  \end{cases}
\end{equation*}
Where we have
\begin{align*}
  \Gamma(\alpha) &= \int_{0}^{\infty}x^{\alpha -1}e^(-x) dx \\
                 &= (\alpha -1)!
\end{align*}
\subsection{Moment Generating Function $M(t)=E(e^{tX})$}

\begin{equation*}
    M(t)=\frac{\lambda^{\alpha}}{(\lambda -t)^{\alpha}}
\end{equation*}

\subsection{$\bm{E(X)}$}

\begin{equation*}
  E(X) = \frac{\alpha}{\lambda}
\end{equation*}

\subsection{$\bm{Var(X)}$}

\begin{equation*}
  Var(X)= \frac{\alpha}{\lambda^{2}}
\end{equation*}
\newpage
\section{Beta $X \sim B(\alpha,\beta)$}
\subsection{Probability Density Function $f(x)$}

\begin{equation*}
  f(x) =
  \begin{cases}
     \frac{x^{\alpha -1} (1-x)^{\beta -1}}{B(\alpha,\beta)} & x \in (0,1) \\
     0 & \text{Otherwise}
  \end{cases}
\end{equation*}
Where we have
\begin{align*}
  B(\alpha,\beta) &= \int_{0}^{1}x^{\alpha -1}(1-x)^{\beta -1} dx
\end{align*}

\subsection{$\bm{E(X)}$}

\begin{equation*}
  E(X) = \frac{\alpha}{\alpha + \beta}
\end{equation*}

\subsection{$\bm{Var(X)}$}

\begin{equation*}
  Var(X)= \frac{\alpha \beta}{(\alpha \beta)^{2} (\alpha + \beta + 1)}
\end{equation*}

\newpage
\section{Normal $X \sim N(\mu,\sigma^{2})$}
\subsection{Probability Density Function $f(x)$}

\begin{equation*}
  f(x) = \frac{1}{\sqrt{2\pi \sigma^{2}}}exp \left [- \frac{(x-\mu)^{2}}{2\sigma^{2}}\right]
\end{equation*}
Where we have $x \in \mathbb{R}$

\subsection{Moment Generating Function $M(t)$}
\begin{equation*}
  M(t) = exp \left [\mu t - \frac{\sigma^{2} t^{2}}{2} \right]
\end{equation*}

\subsection{$\bm{E(X)}$}

\begin{equation*}
  E(X) = \mu
\end{equation*}

\subsection{$\bm{Var(X)}$}

\begin{equation*}
  Var(X)= \sigma^{2}
\end{equation*}

Also for normal distributions we can have that $X$ can become the standard normal distribution $Z \sim N(0,1)$ by the calculation
\begin{equation*}
  \frac{X-\mu}{\sigma^{2}}
\end{equation*}
\end{document}
